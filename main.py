"""
å°è‚¡æ¨è–¦æ©Ÿå™¨äºº - ä¸»ç¨‹å¼
ä½¿ç”¨å‹•èƒ½ç­–ç•¥ç¯©é¸å°è‚¡ï¼Œä¸¦é€é LINE æ¨é€æ¨è–¦æ¸…å–®èˆ‡ K ç·šåœ–
"""
import os
from datetime import datetime, timedelta, timezone

# å°å…¥æ¨¡çµ„
from modules.logger import setup_logger, get_logger
from modules.config import IN_GITHUB_ACTIONS, LINE_USER_ID, GITHUB_PAGES_URL, LINE_NOTIFY_ENABLED
from modules.database import (
    ensure_db,
    ensure_users_table,
    seed_subscribers_from_env,
    upsert_prices,
    load_recent_prices
)
from modules.google_drive import (
    get_drive_service,
    sync_database_from_drive,
    sync_line_ids_from_drive,
    sync_database_to_drive
)
from modules.line_messaging import broadcast_text, broadcast_image, broadcast_button_message, get_active_subscribers
from modules.stock_codes import get_stock_codes, get_stock_name, get_picks_top_k
from modules.stock_data import fetch_prices_yf, pick_stocks
from modules.visualization import plot_stock_charts
from modules.image_upload import upload_image
from modules.html_generator import generate_daily_html, generate_index_html
from modules.breakout_detector import detect_c_pattern, summarize_c_pattern_events

# åˆå§‹åŒ–æ—¥èªŒ
setup_logger()
logger = get_logger(__name__)


def main():
    """ä¸»ç¨‹å¼æµç¨‹"""
    logger.info("=" * 50)
    logger.info("ğŸš€ å°è‚¡æ¨è–¦æ©Ÿå™¨äººè‡ªå‹•åŸ·è¡Œ")
    logger.info("=" * 50)
    start_time = datetime.now()

    try:
        # ===== æ­¥é©Ÿ 1-2: Google Drive è¨­å®šèˆ‡åŒæ­¥ =====
        if IN_GITHUB_ACTIONS:
            logger.info("\nğŸ“Œ æ­¥é©Ÿ 1: GitHub Actions ç’°å¢ƒï¼Œè·³é Google Drive OAuth è¨­å®š")
            logger.info("   (rclone å·²è™•ç†è³‡æ–™åŒæ­¥)")
            drive_service = None
        else:
            logger.info("\nğŸ“Œ æ­¥é©Ÿ 1: è¨­å®š Google Drive é€£ç·š")
            drive_service = get_drive_service()

            logger.info("\nğŸ“Œ æ­¥é©Ÿ 2: å¾ Google Drive åŒæ­¥è³‡æ–™")
            sync_database_from_drive(drive_service)
            sync_line_ids_from_drive(drive_service)

        # ===== æ­¥é©Ÿ 3: åˆå§‹åŒ–è³‡æ–™åº«å’Œè¨‚é–±è€… =====
        logger.info("\nğŸ“Œ æ­¥é©Ÿ 3: å»ºç«‹è³‡æ–™åº«")
        ensure_db()
        ensure_users_table()
        # å–å¾—è¨‚é–±è€…ï¼ˆå„ªå…ˆå¾ line_id.txtï¼Œå†å¾è³‡æ–™åº«ï¼Œæœ€å¾Œç”¨ç’°å¢ƒè®Šæ•¸ï¼‰
        subscribers = get_active_subscribers()

        if not subscribers:
            logger.warning("âš ï¸ ç„¡ä»»ä½•å¯æ¨é€å°è±¡ï¼ˆline_id.txtã€è³‡æ–™åº«ã€ç’°å¢ƒè®Šæ•¸çš†ç‚ºç©ºï¼‰ã€‚")
        else:
            logger.info(f"ğŸ“± æ´»èºè¨‚é–±è€…æ•¸é‡: {len(subscribers)}")
            for sub in subscribers:
                if isinstance(sub, dict):
                    logger.info(f"  - {sub.get('display_name', 'Unknown')}: {sub['user_id']}")
                else:
                    logger.info(f"  - {sub}")

        # ===== æ­¥é©Ÿ 4: ä¸‹è¼‰è‚¡åƒ¹æ•¸æ“š =====
        logger.info("\nğŸ“Œ æ­¥é©Ÿ 4: æª¢æŸ¥ä¸¦ä¸‹è¼‰éœ€è¦çš„æ•¸æ“š")

        # å–å¾—ä»Šæ—¥æ—¥æœŸå’Œæ˜ŸæœŸ
        today_tpe = datetime.now(timezone(timedelta(hours=8))).date()
        today_weekday = today_tpe.weekday()  # 0=é€±ä¸€, 6=é€±æ—¥

        # é€±æœ«ä¸æ›´æ–°è‚¡åƒ¹æ•¸æ“šï¼ˆè‚¡å¸‚ä¼‘å¸‚ï¼‰
        data_updated = False
        if today_weekday >= 5:  # é€±å…­=5, é€±æ—¥=6
            weekday_names = ["é€±ä¸€", "é€±äºŒ", "é€±ä¸‰", "é€±å››", "é€±äº”", "é€±å…­", "é€±æ—¥"]
            logger.info(f"ğŸ—“ï¸  ä»Šæ—¥ç‚º{weekday_names[today_weekday]} ({today_tpe})ï¼Œè‚¡å¸‚ä¼‘å¸‚ï¼Œè·³éæ›´æ–°è‚¡åƒ¹æ•¸æ“š")
            logger.info("â„¹ï¸  ä½¿ç”¨è³‡æ–™åº«ä¸­çš„ç¾æœ‰æ•¸æ“š")
        else:
            codes = get_stock_codes()
            df_new = fetch_prices_yf(codes, lookback_days=120)
            if not df_new.empty:
                upsert_prices(df_new)
                data_updated = True
                logger.info("âœ… è³‡æ–™åº«å·²æ›´æ–°")
            else:
                logger.info("â„¹ï¸  ç„¡éœ€æ›´æ–°è³‡æ–™åº«")

        # ===== æ­¥é©Ÿ 5: é¸è‚¡ =====
        logger.info("\nğŸ“Œ æ­¥é©Ÿ 5: è¼‰å…¥æ•¸æ“šä¸¦ç¯©é¸è‚¡ç¥¨")
        hist = load_recent_prices(days=120)

        # æª¢æŸ¥è³‡æ–™æ˜¯å¦æ­£å¸¸è¼‰å…¥
        if hist.empty:
            logger.warning("âš ï¸  è³‡æ–™åº«ä¸­æ²’æœ‰å¯ç”¨çš„è‚¡åƒ¹æ•¸æ“š")
            logger.warning("   å¯èƒ½åŸå› ï¼š")
            logger.warning("   1. é¦–æ¬¡åŸ·è¡Œï¼Œè³‡æ–™åº«ç‚ºç©º")
            logger.warning("   2. yfinance ä¸‹è¼‰å¤±æ•—")
            logger.warning("   3. ç¶²è·¯é€£ç·šå•é¡Œ")
        else:
            logger.info(f"âœ… è¼‰å…¥ {len(hist)} ç­†æ­·å²è³‡æ–™")
            logger.info(f"   æ¶µè“‹ {hist['code'].nunique()} æ”¯è‚¡ç¥¨")
            logger.info(f"   æ—¥æœŸç¯„åœ: {hist['date'].min()} ~ {hist['date'].max()}")

        top_k = get_picks_top_k()
        picks = pick_stocks(hist, top_k=top_k)
        logger.info(f"ğŸ“Š ç¯©é¸å‡º {len(picks)} æ”¯ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨")

        # ===== æ­¥é©Ÿ 6: è‚¡ç¥¨åˆ†çµ„ï¼ˆä¾äº¤æ˜“é‡èƒ½åˆ†çµ„ï¼‰=====
        logger.info("\nğŸ“Œ æ­¥é©Ÿ 6: å°‡è‚¡ç¥¨åˆ†çµ„ï¼ˆä¾äº¤æ˜“é‡èƒ½ï¼‰")

        if picks.empty:
            group2a = picks  # å‰100å¤§äº¤æ˜“é‡èƒ½
            group2b = picks  # å…¶é¤˜
        else:
            # åªä¿ç•™æ–œç‡ < 0.7 çš„è‚¡ç¥¨ï¼ˆåˆªé™¤åŸæœ¬çš„ group1ï¼‰
            candidates = picks[picks["ma20_slope"] < 0.7].copy()

            if candidates.empty:
                group2a = candidates
                group2b = candidates
            else:
                # è¨ˆç®—äº¤æ˜“é‡èƒ½ï¼ˆäº¤æ˜“é‡ Ã— æ”¶ç›¤åƒ¹ï¼‰
                # å¾æ­·å²è³‡æ–™å–å¾—æœ€è¿‘ä¸€æ—¥çš„æ”¶ç›¤åƒ¹å’Œäº¤æ˜“é‡
                latest_data = hist.sort_values('date').groupby('code').tail(1)
                latest_data['trading_value'] = latest_data['close'] * latest_data['volume']

                # æ‰¾å‡ºå‰100å¤§äº¤æ˜“é‡èƒ½çš„è‚¡ç¥¨ä»£ç¢¼
                top100_codes = latest_data.nlargest(100, 'trading_value')['code'].tolist()

                # åˆ†æˆå…©çµ„
                group2a = candidates[candidates["code"].isin(top100_codes)]  # å‰100å¤§äº¤æ˜“é‡èƒ½
                group2b = candidates[~candidates["code"].isin(top100_codes)]  # å…¶é¤˜

                # é™åˆ¶æ¯çµ„æœ€å¤š 6 æ”¯è‚¡ç¥¨
                MAX_STOCKS_PER_GROUP = 6
                if len(group2a) > MAX_STOCKS_PER_GROUP:
                    logger.info(f"   å‰100å¤§äº¤æ˜“é‡èƒ½çµ„æœ‰ {len(group2a)} æ”¯ï¼Œé™åˆ¶ç‚º {MAX_STOCKS_PER_GROUP} æ”¯")
                    group2a = group2a.head(MAX_STOCKS_PER_GROUP)
                if len(group2b) > MAX_STOCKS_PER_GROUP:
                    logger.info(f"   å…¶é¤˜çµ„æœ‰ {len(group2b)} æ”¯ï¼Œé™åˆ¶ç‚º {MAX_STOCKS_PER_GROUP} æ”¯")
                    group2b = group2b.head(MAX_STOCKS_PER_GROUP)

        logger.info(f"ğŸ“ˆ æœ‰æ©Ÿæœƒå™´ - å‰100å¤§äº¤æ˜“é‡èƒ½ï¼ˆæ–œç‡ < 0.7ï¼‰ï¼š{len(group2a)} æ”¯")
        logger.info(f"ğŸ“Š æœ‰æ©Ÿæœƒå™´ - å…¶é¤˜ï¼ˆæ–œç‡ < 0.7ï¼‰ï¼š{len(group2b)} æ”¯")

        # ===== æ­¥é©Ÿ 6.3: ç ´åº•ç¿»åµæ¸¬ =====
        logger.info("\nğŸ“Œ æ­¥é©Ÿ 6.3: åµæ¸¬ç ´åº•ç¿»å‹æ…‹ï¼ˆCå‹ï¼‰")
        breakout_stocks = []

        # å°æ‰€æœ‰è‚¡ç¥¨é€²è¡Œç ´åº•ç¿»åµæ¸¬
        stock_codes = hist['code'].unique()
        logger.info(f"æƒæ {len(stock_codes)} æ”¯è‚¡ç¥¨å°‹æ‰¾ç ´åº•ç¿»å‹æ…‹...")

        for code in stock_codes:
            stock_df = hist[hist['code'] == code].copy()

            # ç¢ºä¿è³‡æ–™é‡è¶³å¤ 
            if len(stock_df) < 40:
                continue

            try:
                # åŸ·è¡Œç ´åº•ç¿»åµæ¸¬
                result_df = detect_c_pattern(stock_df)
                events = summarize_c_pattern_events(result_df)

                # åªä¿ç•™äº”æ—¥å…§æ”¶å›çš„äº‹ä»¶
                if not events.empty:
                    # è¨ˆç®—äº”æ—¥å‰çš„æ—¥æœŸ
                    five_days_ago = today_tpe - timedelta(days=5)
                    recent_events = events[events['reclaim_date'].dt.date >= five_days_ago]
                    if not recent_events.empty:
                        breakout_stocks.append(recent_events)
                        for _, evt in recent_events.iterrows():
                            logger.info(f"  âœ… {code} ç™¼ç¾ç ´åº•ç¿»äº‹ä»¶ï¼ˆæ”¶å›æ—¥æœŸ: {evt['reclaim_date'].date()}ï¼‰")
            except Exception as e:
                logger.debug(f"  âš ï¸  {code} åµæ¸¬å¤±æ•—: {e}")

        # å½™æ•´ç ´åº•ç¿»è‚¡ç¥¨
        if breakout_stocks:
            import pandas as pd
            breakout_df = pd.concat(breakout_stocks, ignore_index=True)

            # é¡å¤–ç¯©é¸ï¼šä»Šæ—¥è‚¡åƒ¹éœ€åœ¨åæ—¥ç·šä¹‹ä¸Š
            logger.info("ğŸ” ç¯©é¸æ¢ä»¶ï¼šä»Šæ—¥è‚¡åƒ¹éœ€åœ¨åæ—¥ç·šä¹‹ä¸Š")
            filtered_breakout = []
            for idx, row in breakout_df.iterrows():
                code = row['code']
                stock_df = hist[hist['code'] == code].copy()

                # è¨ˆç®—åæ—¥å‡ç·š
                stock_df = stock_df.sort_values('date')
                stock_df['MA10'] = stock_df['close'].rolling(window=10).mean()

                # å–å¾—ä»Šæ—¥è³‡æ–™ï¼ˆæœ€æ–°ä¸€ç­†ï¼‰
                today_data = stock_df.iloc[-1]
                close_price = today_data['close']
                ma10 = today_data['MA10']

                # åˆ¤æ–·ä»Šæ—¥æ”¶ç›¤æ˜¯å¦åœ¨åæ—¥ç·šä¹‹ä¸Š
                if pd.notna(ma10) and close_price > ma10:
                    filtered_breakout.append(row)
                    logger.info(f"  âœ… {code} é€šéç¯©é¸ï¼ˆæ”¶ç›¤: {close_price:.2f}, MA10: {ma10:.2f}ï¼‰")
                else:
                    ma10_str = f"{ma10:.2f}" if pd.notna(ma10) else "N/A"
                    logger.info(f"  âŒ {code} æœªé€šéç¯©é¸ï¼ˆæ”¶ç›¤: {close_price:.2f}, MA10: {ma10_str}ï¼‰")

            if filtered_breakout:
                breakout_df = pd.DataFrame(filtered_breakout)
                # æŒ‰æ”¶å›æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
                breakout_df = breakout_df.sort_values('reclaim_date', ascending=False)
                logger.info(f"ğŸ”¥ äº”æ—¥å…§ç ´åº•ç¿»è‚¡ç¥¨ï¼ˆç¯©é¸å¾Œï¼‰ï¼š{len(breakout_df)} æ”¯")
            else:
                breakout_df = None
                logger.info("â„¹ï¸  äº”æ—¥å…§ç„¡ç¬¦åˆæ¢ä»¶çš„ç ´åº•ç¿»äº‹ä»¶ï¼ˆä»Šæ—¥è‚¡åƒ¹éœ€åœ¨åæ—¥ç·šä¹‹ä¸Šï¼‰")
        else:
            breakout_df = None
            logger.info("â„¹ï¸  äº”æ—¥å…§ç„¡ç ´åº•ç¿»äº‹ä»¶")

        # ===== æ­¥é©Ÿ 6.5: ç”Ÿæˆ K ç·šåœ–ä¸¦è¤‡è£½åˆ° docs è³‡æ–™å¤¾ =====
        logger.info("\nğŸ“Œ æ­¥é©Ÿ 6.5: ç”Ÿæˆ K ç·šåœ–ä¸¦æº–å‚™ GitHub Pages è³‡æ–™")
        date_str = str(today_tpe)
        images_output_dir = os.path.join("docs", "images", date_str)
        os.makedirs(images_output_dir, exist_ok=True)

        # ç”Ÿæˆä¸¦ä¿å­˜ Group2A åœ–ç‰‡ï¼ˆå‰100å¤§äº¤æ˜“é‡èƒ½ï¼‰
        if not group2a.empty:
            generate_and_save_charts(group2a, "æœ‰æ©Ÿæœƒå™´-å‰100å¤§äº¤æ˜“é‡èƒ½", today_tpe, hist, images_output_dir)

        # ç”Ÿæˆä¸¦ä¿å­˜ Group2B åœ–ç‰‡ï¼ˆå…¶é¤˜ï¼‰
        if not group2b.empty:
            generate_and_save_charts(group2b, "æœ‰æ©Ÿæœƒå™´-å…¶é¤˜", today_tpe, hist, images_output_dir)

        # ç”Ÿæˆä¸¦ä¿å­˜ç ´åº•ç¿»è‚¡ç¥¨åœ–ç‰‡
        if breakout_df is not None and not breakout_df.empty:
            logger.info(f"ç”Ÿæˆç ´åº•ç¿»è‚¡ç¥¨ K ç·šåœ–...")
            breakout_codes = breakout_df['code'].unique().tolist()
            generate_and_save_charts_from_codes(breakout_codes, "ç ´åº•ç¿»", today_tpe, hist, images_output_dir)

        # ===== æ­¥é©Ÿ 6.6: ç”Ÿæˆ GitHub Pages HTML =====
        logger.info("\nğŸ“Œ æ­¥é©Ÿ 6.6: ç”Ÿæˆ GitHub Pages HTML")
        try:
            generate_daily_html(date_str, group2a, group2b, output_dir="docs", breakout_df=breakout_df)
            # æ³¨æ„ï¼šindex.html å°‡ç”± workflow çµ±ä¸€ç”Ÿæˆï¼ˆåˆä½µæ­·å²è³‡æ–™å¾Œï¼‰
            logger.info("âœ… GitHub Pages æ¯æ—¥ HTML å·²ç”Ÿæˆ")
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆ HTML å¤±æ•—: {e}")

        # ===== æ­¥é©Ÿ 7: ç™¼é€ LINE è¨Šæ¯ =====
        logger.info("\nğŸ“Œ æ­¥é©Ÿ 7: ç™¼é€ LINE è¨Šæ¯")

        # æª¢æŸ¥ LINE é€šçŸ¥æ˜¯å¦å•Ÿç”¨
        if not LINE_NOTIFY_ENABLED:
            logger.info("ğŸ“´ LINE é€šçŸ¥åŠŸèƒ½å·²é—œé–‰ï¼ˆå¯é€éè¨­å®š LINE_NOTIFY_ENABLED=true å•Ÿç”¨ï¼‰")
        # æª¢æŸ¥æ˜¯å¦ç‚ºé€±æœ«ï¼ˆé€±å…­=5, é€±æ—¥=6ï¼‰
        elif today_weekday >= 5:
            weekday_names = ["é€±ä¸€", "é€±äºŒ", "é€±ä¸‰", "é€±å››", "é€±äº”", "é€±å…­", "é€±æ—¥"]
            logger.info(f"ğŸ—“ï¸  ä»Šæ—¥ç‚º{weekday_names[today_weekday]} ({today_tpe})ï¼Œè‚¡å¸‚ä¼‘å¸‚ï¼Œè·³éç™¼é€è¨Šæ¯")
            logger.info("ğŸ“´ é€±æœ«ä¸ç™¼é€è‚¡ç¥¨æ¨è–¦è¨Šæ¯")
        else:
            # å¹³æ—¥ç™¼é€è¨Šæ¯ - æ”¹ç”¨æŒ‰éˆ•è¨Šæ¯
            date_str = str(today_tpe)

            if group2a.empty and group2b.empty:
                # ç„¡æ¨è–¦æ™‚ä»ç„¶ç™¼é€æŒ‰éˆ•è¨Šæ¯ï¼Œè®“ç”¨æˆ¶å¯ä»¥æŸ¥çœ‹æ­·å²è¨˜éŒ„
                msg = f"ğŸ“‰ {today_tpe}\nä»Šæ—¥ç„¡ç¬¦åˆæ¢ä»¶ä¹‹å°è‚¡æ¨è–¦ã€‚"
                logger.info(f"å°‡ç™¼é€çš„è¨Šæ¯:\n{msg}")
                try:
                    broadcast_text(msg, subscribers)
                    logger.info("âœ… LINE è¨Šæ¯ç™¼é€æˆåŠŸï¼")
                except Exception as e:
                    logger.error(f"âŒ LINE è¨Šæ¯ç™¼é€å¤±æ•—: {e}")
            else:
                # æœ‰æ¨è–¦æ™‚ç™¼é€æŒ‰éˆ•è¨Šæ¯ï¼ˆå«ç¶²ç«™é€£çµå’Œ Postback äº’å‹•ï¼‰
                logger.info(f"ç™¼é€æŒ‰éˆ•è¨Šæ¯ï¼Œé€£çµåˆ° GitHub Pages: {GITHUB_PAGES_URL}")
                try:
                    broadcast_button_message(date_str, GITHUB_PAGES_URL, subscribers)
                    logger.info("âœ… LINE æŒ‰éˆ•è¨Šæ¯ç™¼é€æˆåŠŸï¼")
                except Exception as e:
                    logger.error(f"âŒ LINE æŒ‰éˆ•è¨Šæ¯ç™¼é€å¤±æ•—: {e}")

        # ç„¡è«–æ˜¯å¦ç™¼é€ LINEï¼Œéƒ½ä¿å­˜è‚¡ç¥¨æ¸…å–®åˆ°æª”æ¡ˆï¼ˆä¾›æœªä¾†ä½¿ç”¨ï¼‰
        if not group2a.empty:
            save_stock_list(group2a, "æœ‰æ©Ÿæœƒå™´-å‰100å¤§äº¤æ˜“é‡èƒ½", "ğŸ‘€", today_tpe)
        if not group2b.empty:
            save_stock_list(group2b, "æœ‰æ©Ÿæœƒå™´-å…¶é¤˜", "ğŸ‘€", today_tpe)

        # ===== æ­¥é©Ÿ 8: åŒæ­¥è³‡æ–™åº«åˆ° Google Drive =====
        if IN_GITHUB_ACTIONS:
            logger.info("\nğŸ“Œ æ­¥é©Ÿ 8: GitHub Actions ç’°å¢ƒï¼Œè³‡æ–™åŒæ­¥ç”± rclone è™•ç†")
        elif data_updated and drive_service:
            logger.info("\nğŸ“Œ æ­¥é©Ÿ 8: åŒæ­¥è³‡æ–™åº«åˆ° Google Drive")
            sync_database_to_drive(drive_service)
        elif drive_service:
            logger.info("\næ­¥é©Ÿ 8: è³‡æ–™ç„¡æ›´æ–°ï¼Œè·³é Google Drive åŒæ­¥")
        else:
            logger.info("\næ­¥é©Ÿ 8: Google Drive æœå‹™ä¸å¯ç”¨ï¼Œè·³éåŒæ­¥")

        # ä»»å‹™å®Œæˆ
        end_time = datetime.now()
        execution_time = end_time - start_time
        logger.info("\n" + "=" * 50)
        logger.info(f"ğŸ‰ ä»»å‹™å®Œæˆï¼åŸ·è¡Œæ™‚é–“: {execution_time}")
        logger.info("=" * 50)

    except Exception as e:
        logger.error(f"âŒ ç¨‹å¼åŸ·è¡Œç™¼ç”ŸéŒ¯èª¤: {e}")
        from modules.config import DEBUG_MODE
        if DEBUG_MODE:
            logger.debug(f"è©³ç´°éŒ¯èª¤: {str(e)}", exc_info=True)
        raise
    finally:
        from modules.config import DEBUG_MODE
        if DEBUG_MODE:
            logger.debug("ç¨‹å¼åŸ·è¡ŒçµæŸ")


def generate_and_save_charts(group_df, group_name, today_tpe, hist, output_dir):
    """
    ç”Ÿæˆ K ç·šåœ–ä¸¦ä¿å­˜åˆ°æŒ‡å®šç›®éŒ„

    Args:
        group_df: è‚¡ç¥¨ç¾¤çµ„ DataFrame
        group_name: ç¾¤çµ„åç¨±
        today_tpe: ä»Šæ—¥æ—¥æœŸ
        hist: æ­·å²è‚¡åƒ¹æ•¸æ“š
        output_dir: è¼¸å‡ºç›®éŒ„
    """
    import shutil
    logger.info(f"ç”Ÿæˆã€Œ{group_name}ã€çµ„ K ç·šåœ–...")

    group_codes = group_df["code"].tolist()
    for batch_num in range(0, len(group_codes), 6):
        batch_codes = group_codes[batch_num:batch_num + 6]
        batch_display = ", ".join(batch_codes)
        logger.info(f"  æ­£åœ¨è™•ç†ç¬¬ {batch_num//6 + 1} æ‰¹: {batch_display}")

        chart_path = plot_stock_charts(batch_codes, hist)
        if chart_path:
            # ä¿å­˜åœ–è¡¨åˆ° docs/images/{date}/ è³‡æ–™å¤¾
            # åŠ å…¥æ™‚é–“æˆ³è¨˜é¿å…ç€è¦½å™¨å¿«å–å•é¡Œ
            from datetime import datetime
            timestamp = datetime.now().strftime("%H%M%S")
            chart_filename = f"{group_name}_batch_{batch_num//6 + 1}_{today_tpe}_{timestamp}.png"
            saved_chart_path = os.path.join(output_dir, chart_filename)
            shutil.copy(chart_path, saved_chart_path)
            logger.info(f"  âœ… K ç·šåœ–å·²ä¿å­˜: {saved_chart_path}")

            # åˆªé™¤è‡¨æ™‚æª”æ¡ˆ
            os.unlink(chart_path)
        else:
            logger.warning(f"  âŒ K ç·šåœ–ç”Ÿæˆå¤±æ•—")


def generate_and_save_charts_from_codes(codes_list, group_name, today_tpe, hist, output_dir):
    """
    å¾è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨ç”Ÿæˆ K ç·šåœ–ä¸¦ä¿å­˜åˆ°æŒ‡å®šç›®éŒ„

    Args:
        codes_list: è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨
        group_name: ç¾¤çµ„åç¨±
        today_tpe: ä»Šæ—¥æ—¥æœŸ
        hist: æ­·å²è‚¡åƒ¹æ•¸æ“š
        output_dir: è¼¸å‡ºç›®éŒ„
    """
    import shutil
    logger.info(f"ç”Ÿæˆã€Œ{group_name}ã€çµ„ K ç·šåœ–...")

    for batch_num in range(0, len(codes_list), 6):
        batch_codes = codes_list[batch_num:batch_num + 6]
        batch_display = ", ".join(batch_codes)
        logger.info(f"  æ­£åœ¨è™•ç†ç¬¬ {batch_num//6 + 1} æ‰¹: {batch_display}")

        chart_path = plot_stock_charts(batch_codes, hist)
        if chart_path:
            # ä¿å­˜åœ–è¡¨åˆ° docs/images/{date}/ è³‡æ–™å¤¾
            # åŠ å…¥æ™‚é–“æˆ³è¨˜é¿å…ç€è¦½å™¨å¿«å–å•é¡Œ
            from datetime import datetime
            timestamp = datetime.now().strftime("%H%M%S")
            chart_filename = f"{group_name}_batch_{batch_num//6 + 1}_{today_tpe}_{timestamp}.png"
            saved_chart_path = os.path.join(output_dir, chart_filename)
            shutil.copy(chart_path, saved_chart_path)
            logger.info(f"  âœ… K ç·šåœ–å·²ä¿å­˜: {saved_chart_path}")

            # åˆªé™¤è‡¨æ™‚æª”æ¡ˆ
            os.unlink(chart_path)
        else:
            logger.warning(f"  âŒ K ç·šåœ–ç”Ÿæˆå¤±æ•—")


def save_stock_list(group_df, group_name, emoji, today_tpe):
    """
    ä¿å­˜è‚¡ç¥¨æ¸…å–®åˆ°æ–‡å­—æª”ï¼ˆä¾› Postback äº’å‹•ä½¿ç”¨ï¼‰

    Args:
        group_df: è‚¡ç¥¨ç¾¤çµ„ DataFrame
        group_name: ç¾¤çµ„åç¨±
        emoji: ç¾¤çµ„è¡¨æƒ…ç¬¦è™Ÿ
        today_tpe: ä»Šæ—¥æ—¥æœŸ
    """
    logger.info(f"ä¿å­˜ã€Œ{group_name}ã€çµ„è‚¡ç¥¨æ¸…å–®...")
    lines = [f"{emoji} {group_name} ({today_tpe})"]
    lines.append("ä»¥ä¸‹è‚¡ç¥¨å¯ä»¥åƒè€ƒï¼š\n")
    for i, r in group_df.iterrows():
        stock_name = get_stock_name(r.code)
        lines.append(f"{r.code} {stock_name}")
    msg = "\n".join(lines)

    # å‰µå»ºæ—¥æœŸè³‡æ–™å¤¾
    date_folder = os.path.join("data", str(today_tpe))
    os.makedirs(date_folder, exist_ok=True)

    # ä¿å­˜è‚¡ç¥¨æ¸…å–®åˆ°æ–‡å­—æª”
    list_filename = f"{group_name}_{today_tpe}.txt"
    list_path = os.path.join(date_folder, list_filename)
    with open(list_path, "w", encoding="utf-8") as f:
        f.write(msg)
    logger.info(f"ğŸ“ è‚¡ç¥¨æ¸…å–®å·²ä¿å­˜: {list_path}")


def send_group_messages(group_df, group_name, emoji, today_tpe, subscribers, hist):
    """
    ç™¼é€åˆ†çµ„è¨Šæ¯å’Œåœ–è¡¨

    Args:
        group_df: è‚¡ç¥¨ç¾¤çµ„ DataFrame
        group_name: ç¾¤çµ„åç¨±
        emoji: ç¾¤çµ„è¡¨æƒ…ç¬¦è™Ÿ
        today_tpe: ä»Šæ—¥æ—¥æœŸ
        subscribers: è¨‚é–±è€…åˆ—è¡¨
        hist: æ­·å²è‚¡åƒ¹æ•¸æ“š
    """
    logger.info(f"\nè™•ç†ã€Œ{group_name}ã€çµ„...")
    lines = [f"{emoji} {group_name} ({today_tpe})"]
    lines.append("ä»¥ä¸‹è‚¡ç¥¨å¯ä»¥åƒè€ƒï¼š\n")
    for i, r in group_df.iterrows():
        stock_name = get_stock_name(r.code)
        lines.append(f"{r.code} {stock_name}")
    msg = "\n".join(lines)
    logger.info(f"è¨Šæ¯:\n{msg}")

    # å‰µå»ºæ—¥æœŸè³‡æ–™å¤¾
    date_folder = os.path.join("data", str(today_tpe))
    os.makedirs(date_folder, exist_ok=True)

    # ä¿å­˜è‚¡ç¥¨æ¸…å–®åˆ°æ–‡å­—æª”
    list_filename = f"{group_name}_{today_tpe}.txt"
    list_path = os.path.join(date_folder, list_filename)
    with open(list_path, "w", encoding="utf-8") as f:
        f.write(msg)
    logger.info(f"ğŸ“ è‚¡ç¥¨æ¸…å–®å·²ä¿å­˜: {list_path}")

    try:
        broadcast_text(msg, subscribers)
        logger.info(f"âœ… {group_name}çµ„è¨Šæ¯ç™¼é€æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ {group_name}çµ„è¨Šæ¯ç™¼é€å¤±æ•—: {e}")

    logger.info(f"\nç”Ÿæˆä¸¦ç™¼é€ã€Œ{group_name}ã€çµ„åœ–ç‰‡")
    group_codes = group_df["code"].tolist()
    for batch_num in range(0, len(group_codes), 6):
        batch_codes = group_codes[batch_num:batch_num + 6]
        batch_display = ", ".join(batch_codes)
        logger.info(f"æ­£åœ¨è™•ç†{group_name}ç¬¬ {batch_num//6 + 1} çµ„: {batch_display}")

        chart_path = plot_stock_charts(batch_codes, hist)
        if chart_path:
            # ä¿å­˜åœ–è¡¨åˆ°æ—¥æœŸè³‡æ–™å¤¾
            import shutil
            chart_filename = f"{group_name}_batch_{batch_num//6 + 1}_{today_tpe}.png"
            saved_chart_path = os.path.join(date_folder, chart_filename)
            shutil.copy(chart_path, saved_chart_path)
            logger.info(f"ğŸ’¾ åœ–è¡¨å·²ä¿å­˜: {saved_chart_path}")

            img_url = upload_image(chart_path)
            if img_url:
                try:
                    broadcast_image(img_url, subscribers)
                    logger.info(f"âœ… åœ–è¡¨å·²ç™¼é€åˆ° LINE")
                except Exception as e:
                    logger.error(f"âŒ LINE ç™¼é€å¤±æ•—: {e}")
            else:
                logger.warning(f"âŒ åœ–åºŠä¸Šå‚³å¤±æ•—")

            # åˆªé™¤è‡¨æ™‚æª”æ¡ˆ
            os.unlink(chart_path)
        else:
            logger.warning(f"âŒ åœ–è¡¨ç”Ÿæˆå¤±æ•—")


if __name__ == "__main__":
    main()