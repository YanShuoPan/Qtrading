"""
å°è‚¡æ¨è–¦æ©Ÿå™¨äºº - ä¸»ç¨‹å¼
ä½¿ç”¨å‹•èƒ½ç­–ç•¥ç¯©é¸å°è‚¡ï¼Œä¸¦é€é LINE æ¨é€æ¨è–¦æ¸…å–®èˆ‡ K ç·šåœ–
"""
import os
from datetime import datetime, timedelta, timezone

# å°å…¥æ¨¡çµ„
from modules.logger import setup_logger, get_logger
from modules.config import IN_GITHUB_ACTIONS, LINE_USER_ID, GITHUB_PAGES_URL, LINE_NOTIFY_ENABLED
from modules.database import (
    ensure_db,
    ensure_users_table,
    seed_subscribers_from_env,
    upsert_prices,
    load_recent_prices
)
from modules.google_drive import (
    get_drive_service,
    sync_database_from_drive,
    sync_line_ids_from_drive,
    sync_database_to_drive
)
from modules.line_messaging import broadcast_text, broadcast_image, broadcast_button_message, get_active_subscribers
from modules.stock_codes import get_stock_codes, get_stock_name, get_picks_top_k
from modules.stock_data import fetch_prices_yf, pick_stocks
from modules.visualization import plot_stock_charts
from modules.image_upload import upload_image
from modules.html_generator import generate_daily_html, generate_index_html

# åˆå§‹åŒ–æ—¥èªŒ
setup_logger()
logger = get_logger(__name__)


def main():
    """ä¸»ç¨‹å¼æµç¨‹"""
    logger.info("=" * 50)
    logger.info("ğŸš€ å°è‚¡æ¨è–¦æ©Ÿå™¨äººè‡ªå‹•åŸ·è¡Œ")
    logger.info("=" * 50)
    start_time = datetime.now()

    try:
        # ===== æ­¥é©Ÿ 1-2: Google Drive è¨­å®šèˆ‡åŒæ­¥ =====
        if IN_GITHUB_ACTIONS:
            logger.info("\nğŸ“Œ æ­¥é©Ÿ 1: GitHub Actions ç’°å¢ƒï¼Œè·³é Google Drive OAuth è¨­å®š")
            logger.info("   (rclone å·²è™•ç†è³‡æ–™åŒæ­¥)")
            drive_service = None
        else:
            logger.info("\nğŸ“Œ æ­¥é©Ÿ 1: è¨­å®š Google Drive é€£ç·š")
            drive_service = get_drive_service()

            logger.info("\nğŸ“Œ æ­¥é©Ÿ 2: å¾ Google Drive åŒæ­¥è³‡æ–™")
            sync_database_from_drive(drive_service)
            sync_line_ids_from_drive(drive_service)

        # ===== æ­¥é©Ÿ 3: åˆå§‹åŒ–è³‡æ–™åº«å’Œè¨‚é–±è€… =====
        logger.info("\nğŸ“Œ æ­¥é©Ÿ 3: å»ºç«‹è³‡æ–™åº«")
        ensure_db()
        ensure_users_table()
        # å–å¾—è¨‚é–±è€…ï¼ˆå„ªå…ˆå¾ line_id.txtï¼Œå†å¾è³‡æ–™åº«ï¼Œæœ€å¾Œç”¨ç’°å¢ƒè®Šæ•¸ï¼‰
        subscribers = get_active_subscribers()

        if not subscribers:
            logger.warning("âš ï¸ ç„¡ä»»ä½•å¯æ¨é€å°è±¡ï¼ˆline_id.txtã€è³‡æ–™åº«ã€ç’°å¢ƒè®Šæ•¸çš†ç‚ºç©ºï¼‰ã€‚")
        else:
            logger.info(f"ğŸ“± æ´»èºè¨‚é–±è€…æ•¸é‡: {len(subscribers)}")
            for sub in subscribers:
                if isinstance(sub, dict):
                    logger.info(f"  - {sub.get('display_name', 'Unknown')}: {sub['user_id']}")
                else:
                    logger.info(f"  - {sub}")

        # ===== æ­¥é©Ÿ 4: ä¸‹è¼‰è‚¡åƒ¹æ•¸æ“š =====
        logger.info("\nğŸ“Œ æ­¥é©Ÿ 4: æª¢æŸ¥ä¸¦ä¸‹è¼‰éœ€è¦çš„æ•¸æ“š")

        # å–å¾—ä»Šæ—¥æ—¥æœŸå’Œæ˜ŸæœŸ
        today_tpe = datetime.now(timezone(timedelta(hours=8))).date()
        today_weekday = today_tpe.weekday()  # 0=é€±ä¸€, 6=é€±æ—¥

        # é€±æœ«ä¸æ›´æ–°è‚¡åƒ¹æ•¸æ“šï¼ˆè‚¡å¸‚ä¼‘å¸‚ï¼‰
        data_updated = False
        if today_weekday >= 5:  # é€±å…­=5, é€±æ—¥=6
            weekday_names = ["é€±ä¸€", "é€±äºŒ", "é€±ä¸‰", "é€±å››", "é€±äº”", "é€±å…­", "é€±æ—¥"]
            logger.info(f"ğŸ—“ï¸  ä»Šæ—¥ç‚º{weekday_names[today_weekday]} ({today_tpe})ï¼Œè‚¡å¸‚ä¼‘å¸‚ï¼Œè·³éæ›´æ–°è‚¡åƒ¹æ•¸æ“š")
            logger.info("â„¹ï¸  ä½¿ç”¨è³‡æ–™åº«ä¸­çš„ç¾æœ‰æ•¸æ“š")
        else:
            codes = get_stock_codes()
            df_new = fetch_prices_yf(codes, lookback_days=120)
            if not df_new.empty:
                upsert_prices(df_new)
                data_updated = True
                logger.info("âœ… è³‡æ–™åº«å·²æ›´æ–°")
            else:
                logger.info("â„¹ï¸  ç„¡éœ€æ›´æ–°è³‡æ–™åº«")

        # ===== æ­¥é©Ÿ 5: é¸è‚¡ =====
        logger.info("\nğŸ“Œ æ­¥é©Ÿ 5: è¼‰å…¥æ•¸æ“šä¸¦ç¯©é¸è‚¡ç¥¨")
        hist = load_recent_prices(days=120)
        top_k = get_picks_top_k()
        picks = pick_stocks(hist, top_k=top_k)
        logger.debug(f"è¼‰å…¥ {len(hist)} ç­†æ­·å²è³‡æ–™")
        logger.debug(f"ç¯©é¸å‡º {len(picks)} æ”¯ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨")

        # ===== æ­¥é©Ÿ 6: è‚¡ç¥¨åˆ†çµ„ =====
        logger.info("\nğŸ“Œ æ­¥é©Ÿ 6: å°‡è‚¡ç¥¨åˆ†çµ„")

        if picks.empty:
            group1 = picks
            group2 = picks
        else:
            group1 = picks[(picks["ma20_slope"] >= 0.5) & (picks["ma20_slope"] < 1)]
            group2 = picks[picks["ma20_slope"] < 0.5]

        logger.info(f"ğŸ“ˆ å¥½åƒè »å¼·çš„ï¼ˆæ–œç‡ 0.5-1ï¼‰ï¼š{len(group1)} æ”¯")
        logger.info(f"ğŸ“Š æœ‰æ©Ÿæœƒå™´ è§€å¯Ÿä¸€ä¸‹ï¼ˆæ–œç‡ < 0.5ï¼‰ï¼š{len(group2)} æ”¯")

        # ===== æ­¥é©Ÿ 6.5: ç”Ÿæˆ K ç·šåœ–ä¸¦è¤‡è£½åˆ° docs è³‡æ–™å¤¾ =====
        logger.info("\nğŸ“Œ æ­¥é©Ÿ 6.5: ç”Ÿæˆ K ç·šåœ–ä¸¦æº–å‚™ GitHub Pages è³‡æ–™")
        date_str = str(today_tpe)
        images_output_dir = os.path.join("docs", "images", date_str)
        os.makedirs(images_output_dir, exist_ok=True)

        # ç”Ÿæˆä¸¦ä¿å­˜ Group1 åœ–ç‰‡
        if not group1.empty:
            generate_and_save_charts(group1, "å¥½åƒè »å¼·çš„", today_tpe, hist, images_output_dir)

        # ç”Ÿæˆä¸¦ä¿å­˜ Group2 åœ–ç‰‡
        if not group2.empty:
            generate_and_save_charts(group2, "æœ‰æ©Ÿæœƒå™´ è§€å¯Ÿä¸€ä¸‹", today_tpe, hist, images_output_dir)

        # ===== æ­¥é©Ÿ 6.6: ç”Ÿæˆ GitHub Pages HTML =====
        logger.info("\nğŸ“Œ æ­¥é©Ÿ 6.6: ç”Ÿæˆ GitHub Pages HTML")
        try:
            generate_daily_html(date_str, group1, group2, output_dir="docs")
            # æ³¨æ„ï¼šindex.html å°‡ç”± workflow çµ±ä¸€ç”Ÿæˆï¼ˆåˆä½µæ­·å²è³‡æ–™å¾Œï¼‰
            logger.info("âœ… GitHub Pages æ¯æ—¥ HTML å·²ç”Ÿæˆ")
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆ HTML å¤±æ•—: {e}")

        # ===== æ­¥é©Ÿ 7: ç™¼é€ LINE è¨Šæ¯ =====
        logger.info("\nğŸ“Œ æ­¥é©Ÿ 7: ç™¼é€ LINE è¨Šæ¯")

        # æª¢æŸ¥ LINE é€šçŸ¥æ˜¯å¦å•Ÿç”¨
        if not LINE_NOTIFY_ENABLED:
            logger.info("ğŸ“´ LINE é€šçŸ¥åŠŸèƒ½å·²é—œé–‰ï¼ˆå¯é€éè¨­å®š LINE_NOTIFY_ENABLED=true å•Ÿç”¨ï¼‰")
        # æª¢æŸ¥æ˜¯å¦ç‚ºé€±æœ«ï¼ˆé€±å…­=5, é€±æ—¥=6ï¼‰
        elif today_weekday >= 5:
            weekday_names = ["é€±ä¸€", "é€±äºŒ", "é€±ä¸‰", "é€±å››", "é€±äº”", "é€±å…­", "é€±æ—¥"]
            logger.info(f"ğŸ—“ï¸  ä»Šæ—¥ç‚º{weekday_names[today_weekday]} ({today_tpe})ï¼Œè‚¡å¸‚ä¼‘å¸‚ï¼Œè·³éç™¼é€è¨Šæ¯")
            logger.info("ğŸ“´ é€±æœ«ä¸ç™¼é€è‚¡ç¥¨æ¨è–¦è¨Šæ¯")
        else:
            # å¹³æ—¥ç™¼é€è¨Šæ¯ - æ”¹ç”¨æŒ‰éˆ•è¨Šæ¯
            date_str = str(today_tpe)

            if group1.empty and group2.empty:
                # ç„¡æ¨è–¦æ™‚ä»ç„¶ç™¼é€æŒ‰éˆ•è¨Šæ¯ï¼Œè®“ç”¨æˆ¶å¯ä»¥æŸ¥çœ‹æ­·å²è¨˜éŒ„
                msg = f"ğŸ“‰ {today_tpe}\nä»Šæ—¥ç„¡ç¬¦åˆæ¢ä»¶ä¹‹å°è‚¡æ¨è–¦ã€‚"
                logger.info(f"å°‡ç™¼é€çš„è¨Šæ¯:\n{msg}")
                try:
                    broadcast_text(msg, subscribers)
                    logger.info("âœ… LINE è¨Šæ¯ç™¼é€æˆåŠŸï¼")
                except Exception as e:
                    logger.error(f"âŒ LINE è¨Šæ¯ç™¼é€å¤±æ•—: {e}")
            else:
                # æœ‰æ¨è–¦æ™‚ç™¼é€æŒ‰éˆ•è¨Šæ¯ï¼ˆå«ç¶²ç«™é€£çµå’Œ Postback äº’å‹•ï¼‰
                logger.info(f"ç™¼é€æŒ‰éˆ•è¨Šæ¯ï¼Œé€£çµåˆ° GitHub Pages: {GITHUB_PAGES_URL}")
                try:
                    broadcast_button_message(date_str, GITHUB_PAGES_URL, subscribers)
                    logger.info("âœ… LINE æŒ‰éˆ•è¨Šæ¯ç™¼é€æˆåŠŸï¼")
                except Exception as e:
                    logger.error(f"âŒ LINE æŒ‰éˆ•è¨Šæ¯ç™¼é€å¤±æ•—: {e}")

        # ç„¡è«–æ˜¯å¦ç™¼é€ LINEï¼Œéƒ½ä¿å­˜è‚¡ç¥¨æ¸…å–®åˆ°æª”æ¡ˆï¼ˆä¾›æœªä¾†ä½¿ç”¨ï¼‰
        if not group1.empty:
            save_stock_list(group1, "å¥½åƒè »å¼·çš„", "ğŸ’ª", today_tpe)
        if not group2.empty:
            save_stock_list(group2, "æœ‰æ©Ÿæœƒå™´ è§€å¯Ÿä¸€ä¸‹", "ğŸ‘€", today_tpe)

        # ===== æ­¥é©Ÿ 8: åŒæ­¥è³‡æ–™åº«åˆ° Google Drive =====
        if IN_GITHUB_ACTIONS:
            logger.info("\nğŸ“Œ æ­¥é©Ÿ 8: GitHub Actions ç’°å¢ƒï¼Œè³‡æ–™åŒæ­¥ç”± rclone è™•ç†")
        elif data_updated and drive_service:
            logger.info("\nğŸ“Œ æ­¥é©Ÿ 8: åŒæ­¥è³‡æ–™åº«åˆ° Google Drive")
            sync_database_to_drive(drive_service)
        elif drive_service:
            logger.info("\næ­¥é©Ÿ 8: è³‡æ–™ç„¡æ›´æ–°ï¼Œè·³é Google Drive åŒæ­¥")
        else:
            logger.info("\næ­¥é©Ÿ 8: Google Drive æœå‹™ä¸å¯ç”¨ï¼Œè·³éåŒæ­¥")

        # ä»»å‹™å®Œæˆ
        end_time = datetime.now()
        execution_time = end_time - start_time
        logger.info("\n" + "=" * 50)
        logger.info(f"ğŸ‰ ä»»å‹™å®Œæˆï¼åŸ·è¡Œæ™‚é–“: {execution_time}")
        logger.info("=" * 50)

    except Exception as e:
        logger.error(f"âŒ ç¨‹å¼åŸ·è¡Œç™¼ç”ŸéŒ¯èª¤: {e}")
        from modules.config import DEBUG_MODE
        if DEBUG_MODE:
            logger.debug(f"è©³ç´°éŒ¯èª¤: {str(e)}", exc_info=True)
        raise
    finally:
        from modules.config import DEBUG_MODE
        if DEBUG_MODE:
            logger.debug("ç¨‹å¼åŸ·è¡ŒçµæŸ")


def generate_and_save_charts(group_df, group_name, today_tpe, hist, output_dir):
    """
    ç”Ÿæˆ K ç·šåœ–ä¸¦ä¿å­˜åˆ°æŒ‡å®šç›®éŒ„

    Args:
        group_df: è‚¡ç¥¨ç¾¤çµ„ DataFrame
        group_name: ç¾¤çµ„åç¨±
        today_tpe: ä»Šæ—¥æ—¥æœŸ
        hist: æ­·å²è‚¡åƒ¹æ•¸æ“š
        output_dir: è¼¸å‡ºç›®éŒ„
    """
    import shutil
    logger.info(f"ç”Ÿæˆã€Œ{group_name}ã€çµ„ K ç·šåœ–...")

    group_codes = group_df["code"].tolist()
    for batch_num in range(0, len(group_codes), 6):
        batch_codes = group_codes[batch_num:batch_num + 6]
        batch_display = ", ".join(batch_codes)
        logger.info(f"  æ­£åœ¨è™•ç†ç¬¬ {batch_num//6 + 1} æ‰¹: {batch_display}")

        chart_path = plot_stock_charts(batch_codes, hist)
        if chart_path:
            # ä¿å­˜åœ–è¡¨åˆ° docs/images/{date}/ è³‡æ–™å¤¾
            # åŠ å…¥æ™‚é–“æˆ³è¨˜é¿å…ç€è¦½å™¨å¿«å–å•é¡Œ
            from datetime import datetime
            timestamp = datetime.now().strftime("%H%M%S")
            chart_filename = f"{group_name}_batch_{batch_num//6 + 1}_{today_tpe}_{timestamp}.png"
            saved_chart_path = os.path.join(output_dir, chart_filename)
            shutil.copy(chart_path, saved_chart_path)
            logger.info(f"  âœ… K ç·šåœ–å·²ä¿å­˜: {saved_chart_path}")

            # åˆªé™¤è‡¨æ™‚æª”æ¡ˆ
            os.unlink(chart_path)
        else:
            logger.warning(f"  âŒ K ç·šåœ–ç”Ÿæˆå¤±æ•—")


def save_stock_list(group_df, group_name, emoji, today_tpe):
    """
    ä¿å­˜è‚¡ç¥¨æ¸…å–®åˆ°æ–‡å­—æª”ï¼ˆä¾› Postback äº’å‹•ä½¿ç”¨ï¼‰

    Args:
        group_df: è‚¡ç¥¨ç¾¤çµ„ DataFrame
        group_name: ç¾¤çµ„åç¨±
        emoji: ç¾¤çµ„è¡¨æƒ…ç¬¦è™Ÿ
        today_tpe: ä»Šæ—¥æ—¥æœŸ
    """
    logger.info(f"ä¿å­˜ã€Œ{group_name}ã€çµ„è‚¡ç¥¨æ¸…å–®...")
    lines = [f"{emoji} {group_name} ({today_tpe})"]
    lines.append("ä»¥ä¸‹è‚¡ç¥¨å¯ä»¥åƒè€ƒï¼š\n")
    for i, r in group_df.iterrows():
        stock_name = get_stock_name(r.code)
        lines.append(f"{r.code} {stock_name}")
    msg = "\n".join(lines)

    # å‰µå»ºæ—¥æœŸè³‡æ–™å¤¾
    date_folder = os.path.join("data", str(today_tpe))
    os.makedirs(date_folder, exist_ok=True)

    # ä¿å­˜è‚¡ç¥¨æ¸…å–®åˆ°æ–‡å­—æª”
    list_filename = f"{group_name}_{today_tpe}.txt"
    list_path = os.path.join(date_folder, list_filename)
    with open(list_path, "w", encoding="utf-8") as f:
        f.write(msg)
    logger.info(f"ğŸ“ è‚¡ç¥¨æ¸…å–®å·²ä¿å­˜: {list_path}")


def send_group_messages(group_df, group_name, emoji, today_tpe, subscribers, hist):
    """
    ç™¼é€åˆ†çµ„è¨Šæ¯å’Œåœ–è¡¨

    Args:
        group_df: è‚¡ç¥¨ç¾¤çµ„ DataFrame
        group_name: ç¾¤çµ„åç¨±
        emoji: ç¾¤çµ„è¡¨æƒ…ç¬¦è™Ÿ
        today_tpe: ä»Šæ—¥æ—¥æœŸ
        subscribers: è¨‚é–±è€…åˆ—è¡¨
        hist: æ­·å²è‚¡åƒ¹æ•¸æ“š
    """
    logger.info(f"\nè™•ç†ã€Œ{group_name}ã€çµ„...")
    lines = [f"{emoji} {group_name} ({today_tpe})"]
    lines.append("ä»¥ä¸‹è‚¡ç¥¨å¯ä»¥åƒè€ƒï¼š\n")
    for i, r in group_df.iterrows():
        stock_name = get_stock_name(r.code)
        lines.append(f"{r.code} {stock_name}")
    msg = "\n".join(lines)
    logger.info(f"è¨Šæ¯:\n{msg}")

    # å‰µå»ºæ—¥æœŸè³‡æ–™å¤¾
    date_folder = os.path.join("data", str(today_tpe))
    os.makedirs(date_folder, exist_ok=True)

    # ä¿å­˜è‚¡ç¥¨æ¸…å–®åˆ°æ–‡å­—æª”
    list_filename = f"{group_name}_{today_tpe}.txt"
    list_path = os.path.join(date_folder, list_filename)
    with open(list_path, "w", encoding="utf-8") as f:
        f.write(msg)
    logger.info(f"ğŸ“ è‚¡ç¥¨æ¸…å–®å·²ä¿å­˜: {list_path}")

    try:
        broadcast_text(msg, subscribers)
        logger.info(f"âœ… {group_name}çµ„è¨Šæ¯ç™¼é€æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ {group_name}çµ„è¨Šæ¯ç™¼é€å¤±æ•—: {e}")

    logger.info(f"\nç”Ÿæˆä¸¦ç™¼é€ã€Œ{group_name}ã€çµ„åœ–ç‰‡")
    group_codes = group_df["code"].tolist()
    for batch_num in range(0, len(group_codes), 6):
        batch_codes = group_codes[batch_num:batch_num + 6]
        batch_display = ", ".join(batch_codes)
        logger.info(f"æ­£åœ¨è™•ç†{group_name}ç¬¬ {batch_num//6 + 1} çµ„: {batch_display}")

        chart_path = plot_stock_charts(batch_codes, hist)
        if chart_path:
            # ä¿å­˜åœ–è¡¨åˆ°æ—¥æœŸè³‡æ–™å¤¾
            import shutil
            chart_filename = f"{group_name}_batch_{batch_num//6 + 1}_{today_tpe}.png"
            saved_chart_path = os.path.join(date_folder, chart_filename)
            shutil.copy(chart_path, saved_chart_path)
            logger.info(f"ğŸ’¾ åœ–è¡¨å·²ä¿å­˜: {saved_chart_path}")

            img_url = upload_image(chart_path)
            if img_url:
                try:
                    broadcast_image(img_url, subscribers)
                    logger.info(f"âœ… åœ–è¡¨å·²ç™¼é€åˆ° LINE")
                except Exception as e:
                    logger.error(f"âŒ LINE ç™¼é€å¤±æ•—: {e}")
            else:
                logger.warning(f"âŒ åœ–åºŠä¸Šå‚³å¤±æ•—")

            # åˆªé™¤è‡¨æ™‚æª”æ¡ˆ
            os.unlink(chart_path)
        else:
            logger.warning(f"âŒ åœ–è¡¨ç”Ÿæˆå¤±æ•—")


if __name__ == "__main__":
    main()